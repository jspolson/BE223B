{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import (wordnet, stopwords)\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import (confusion_matrix, \n",
    "                             recall_score, \n",
    "                             f1_score, \n",
    "                             accuracy_score, \n",
    "                             precision_score,\n",
    "                             roc_curve, auc, roc_auc_score)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jsons_data = pd.DataFrame(columns = ['user_record_id', 'text', 'likes', 'replies', 'retweets'])\n",
    "tweets_concat = pd.DataFrame(columns = ['user_id', 'n_tweets', 'text', 'likes', 'replies', 'retweets'])\n",
    "\n",
    "directory = '/Users/jenniferpolson/Documents/School/2018-W/BE 223B/Project 1/tweet_files/'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.json'):\n",
    "        df = pd.DataFrame(json.load(open(directory + str(filename))))\n",
    "        df['tweet_id'] = df['user_record_id'].map(str) + '_' + df.index.astype(str)\n",
    "        jsons_data = jsons_data.append(df) \n",
    "        tweets_concat = tweets_concat.append({'user_id':df.user_record_id.iloc[0], \n",
    "                                              'n_tweets': len(df.index),\n",
    "                                              'text':df['text'].str.cat(sep=', '), \n",
    "                                              'likes':df.likes.astype(int).sum(), \n",
    "                                              'replies':df.replies.astype(int).sum(), \n",
    "                                              'retweets':df.retweets.astype(int).sum()}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Karthik's code\n",
    "class RepeatReplacer(object):\n",
    "    \"\"\" Removes repeating characters until a valid word is found.\n",
    "    >>> replacer = RepeatReplacer()\n",
    "    >>> replacer.replace(‘looooove’)\n",
    "    ‘love’\n",
    "    >>> replacer.replace(‘oooooh’)\n",
    "    ‘ooh’\n",
    "    >>> replacer.replace(‘goose’)\n",
    "    ‘goose’\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.repeat_regexp = re.compile(r'(\\w*)(\\w)\\2(\\w*)')\n",
    "        self.repl = r'\\1\\2\\3'\n",
    "\n",
    "    def replace(self, word):\n",
    "        if wordnet.synsets(word):\n",
    "            return word\n",
    "\n",
    "        repl_word = self.repeat_regexp.sub(self.repl, word)\n",
    "\n",
    "        if repl_word != word:\n",
    "            return self.replace(repl_word)\n",
    "        else:\n",
    "            return repl_word\n",
    "    \n",
    "    \n",
    "def process_tweets (tweets, colname):\n",
    "    processed_text = []\n",
    "    for text in tweets[colname]:\n",
    "        #replace hyperlinks - leaves xa0 off for some reason\n",
    "        test = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', ' hyperlink ', text).replace('\\xa0', '')\n",
    "        #replace mentions\n",
    "        test = re.sub(r'(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)', ' mention ', test)\n",
    "        #replace picture links\n",
    "        test = re.sub(r'pic.twitter\\S+', ' image ', test)\n",
    "        test = \"\".join((char for char in test if char not in string.punctuation + '—–-…’0123456789')).lower()\\\n",
    "\n",
    "        #remove repeat letters\n",
    "        tokens = [RepeatReplacer().replace(w) for w in word_tokenize(test)]\n",
    "        #employ stemmer\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "        tokens = [stemmer.stem(w) for w in tokens]\n",
    "        #get rid of stop words\n",
    "        filtered_string = ' '.join([w for w in tokens\n",
    "                             if not w in set(stopwords.words('english'))])\n",
    "\n",
    "        processed_text.append(filtered_string)\n",
    "\n",
    "    tweets[colname] = processed_text\n",
    "    \n",
    "    return tweets\n",
    "\n",
    "def tfidf_vector (tweets, colname, n_terms):\n",
    "    tf = TfidfVectorizer(analyzer='word', min_df = 0, stop_words = 'english')\n",
    "\n",
    "    tfidf_matrix =  tf.fit_transform(tweets[colname])\n",
    "    feature_names = tf.get_feature_names() \n",
    "    dense = tfidf_matrix.todense()\n",
    "    df = pd.DataFrame(dense)\n",
    "    df.columns = feature_names\n",
    "    df = df.append(df.sum(numeric_only=True), ignore_index=True)\n",
    "\n",
    "    filtered_terms = df.transpose().nlargest(n_terms, df.transpose().iloc[:,:(len(df)-1)]).transpose()\n",
    "    return filtered_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentiment_analysis(text):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    neg = []\n",
    "    neu = []\n",
    "    pos = []\n",
    "    for sentence in text:\n",
    "        vs = analyzer.polarity_scores(sentence)\n",
    "        neg.append(vs['neg'])\n",
    "        neu.append(vs['neu'])\n",
    "        pos.append(vs['pos'])\n",
    "    return neg, pos, neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_tweets(tweets_concat, 'text')\n",
    "new_features = pd.concat([df, tfidf_vector(df, 'text', 100)[:-1]], axis = 1)\n",
    "\n",
    "new_features['Negative Sentiment'], new_features['Positive Sentiment'], new_features['Neutral Sentiment'] = sentiment_analysis(tweets_concat.text)\n",
    "#match the labels\n",
    "labels = pd.read_csv(\"twitter-data-deidentified.csv\")\n",
    "labels.index = labels.record_id\n",
    "new_features.index = new_features.user_id\n",
    "full_data = pd.merge(new_features, labels, how='inner', on=None, left_on=None, right_on=None,\n",
    "                     left_index=True, right_index=True).drop(['record_id', 'user_id'], axis=1)\n",
    "#binarize\n",
    "full_data['binary_label'] = (full_data['variable'] >= 3).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split into folds\n",
    "def create_folds(full_data, n): \n",
    "    nlist = list(range(0,len(full_data)-1))\n",
    "    random.shuffle(nlist)\n",
    "    fold_size = len(nlist) / n\n",
    "    ints = [nlist[int(round(fold_size * i)): \n",
    "                  int(round(fold_size * (i + 1)))] \n",
    "             for i in range(n)]\n",
    "    fold = [full_data.iloc[ints[i],:] for i in range(n)]\n",
    "    return fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_metrics (test, label, pred):\n",
    "    acc = accuracy_score(test[label], test[pred])\n",
    "    f1 = f1_score(test[label], test[pred])\n",
    "    prec = precision_score(test[label], test[pred])\n",
    "    rec = recall_score(test[label], test[pred])\n",
    "    roc_auc = roc_auc_score(test[label], test[pred])\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(test[label], test[pred]).ravel()\n",
    "    \n",
    "    return roc_auc, acc, prec, rec, f1\n",
    "\n",
    "def rfc_metrics (test, label, pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(test[label], test[pred]).ravel()\n",
    "    \n",
    "    roc_auc, acc, prec, rec, f1 = binary_metrics(test, label, pred)\n",
    "    \n",
    "    roc = roc_curve(test[label], test[pred])\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    n_classes = test[label].nunique()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(test[label], test[pred])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test[label].ravel(), test[pred].ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    lw = 2\n",
    "    plt.plot(fpr[1], tpr[1], color='gold',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    show_confusion_matrix(test, label, pred)\n",
    "    \n",
    "    return details\n",
    "\n",
    "def show_confusion_matrix(test, label, pred):\n",
    "    \n",
    "    C = confusion_matrix(test[label], test[pred])\n",
    "    tn, fp, fn, tp = C.ravel()\n",
    "    \n",
    "    NP = fn+tp # Num positive examples\n",
    "    NN = tn+fp # Num negative examples\n",
    "    N  = NP+NN\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax  = fig.add_subplot(111)\n",
    "    ax.imshow(C, cmap=plt.cm.gray)\n",
    "\n",
    "    # Draw the grid boxes\n",
    "    ax.set_xlim(-0.5,2.5)\n",
    "    ax.set_ylim(2.5,-0.5)\n",
    "    ax.plot([-0.5,2.5],[0.5,0.5], '-k', lw=2)\n",
    "    ax.plot([-0.5,2.5],[1.5,1.5], '-k', lw=2)\n",
    "    ax.plot([0.5,0.5],[-0.5,2.5], '-k', lw=2)\n",
    "    ax.plot([1.5,1.5],[-0.5,2.5], '-k', lw=2)\n",
    "\n",
    "\n",
    "    # Set xlabels\n",
    "    ax.set_xlabel('Predicted Label', fontsize=16)\n",
    "    ax.set_xticks([0,1,2])\n",
    "    ax.set_xticklabels(['Show', 'No Show'])\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.xaxis.tick_top()\n",
    "    # These coordinate might require some tinkering. Ditto for y, below.\n",
    "    ax.xaxis.set_label_coords(0.34,1.06)\n",
    "\n",
    "    # Set ylabels\n",
    "    ax.set_ylabel('True Label', fontsize=16, rotation=90)\n",
    "    ax.set_yticklabels(['Show', 'No Show'])\n",
    "    ax.set_yticks([0,1,2])\n",
    "    ax.yaxis.set_label_coords(-0.09,0.65)\n",
    "\n",
    "\n",
    "    # Fill in initial metrics: tp, tn, etc...\n",
    "    ax.text(0,0,'True Negatives: %d\\n(Total Negatives: %d)'%(tn,NN),\n",
    "            va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(0,1,'False Negatives: %d'%fn,\n",
    "            va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(1,0,'False Positives: %d'%fp,\n",
    "           va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(1,1,'True Positives: %d\\n(Total Positives: %d)'%(tp,NP),\n",
    "            va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    # Fill in secondary metrics: accuracy, true pos rate, etc...\n",
    "    ax.text(2,0,'True Negative Rate' + '\\n' +'(Specificity):%.2f'%(tn / (fp+tn+0.)),\n",
    "            va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(2,1,'True Positive Rate' + '\\n' + '(Sensitivity):%.2f'%(tp / (tp+fn+0.)),\n",
    "            va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(2,2,'F-1 Score: %.2f'%(round(2*tp/((2*tp) + fp + fn),3)),\n",
    "            va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(0,2,'Negative Predictive ' + '\\n' + 'Value: %.2f'%(1-fn/(fn+tn+0.)),\n",
    "           va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "    ax.text(1,2,'Positive Predictive ' + '\\n' + 'Value: %.2f'%(tp/(tp+fp+0.)),\n",
    "            va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model(full_data, test, label, pred, plot = False):\n",
    "\n",
    "    train = pd.concat([full_data, test]).drop_duplicates(keep=False)\n",
    "    trainArr = train.drop(['variable', 'binary_label', 'text'], axis = 1).as_matrix()\n",
    "    trainRes = train.as_matrix(['binary_label'])\n",
    "    testArr = test.drop(['variable', 'binary_label'], axis = 1).as_matrix()\n",
    "    #gridsearch\n",
    "\n",
    "    param_test1 = {'C':[0.001,0.01,0.1,1,10,100],\n",
    "                  }\n",
    "    gridsearch = GridSearchCV(estimator = LogisticRegression(),\n",
    "                              param_grid = param_test1)\n",
    "\n",
    "    gridsearch.fit(trainArr, \n",
    "                   trainRes)\n",
    "\n",
    "    clf_lr = LogisticRegression(C=list(gridsearch.best_params_.values())[0])\n",
    "    data = test\n",
    "    clf_lr.fit(trainArr, trainRes)\n",
    "    data[pred] = clf_lr.predict(testArr)\n",
    "    \n",
    "    if plot:\n",
    "        roc_auc, acc, prec, rec, f1 = rfc_metrics(data, label, pred)\n",
    "    else:\n",
    "        roc_auc, acc, prec, rec, f1 = binary_metrics(data, label, pred)\n",
    "    \n",
    "    return [roc_auc, acc, prec, rec, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold1, fold2, fold3, fold4, fold5 = create_folds(full_data.drop('text', axis = 1),5)\n",
    "label, pred = 'binary_label', 'predictions'\n",
    "\n",
    "b1 = run_model(full_data, fold1, label, pred)\n",
    "b2 = run_model(full_data, fold2, label, pred)\n",
    "b3 = run_model(full_data, fold3, label, pred)\n",
    "b4 = run_model(full_data, fold4, label, pred)\n",
    "b5 = run_model(full_data, fold5, label, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC AUC Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F-1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold 1</th>\n",
       "      <td>0.457576</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 2</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 3</th>\n",
       "      <td>0.412121</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 4</th>\n",
       "      <td>0.455128</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 5</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ROC AUC Score  Accuracy    Recall  Precision  F-1 Score\n",
       "Fold 1       0.457576  0.500000  0.333333   0.181818   0.235294\n",
       "Fold 2       0.625000  0.520000  1.000000   0.250000   0.400000\n",
       "Fold 3       0.412121  0.461538  0.200000   0.090909   0.125000\n",
       "Fold 4       0.455128  0.440000  0.333333   0.076923   0.125000\n",
       "Fold 5       0.571429  0.538462  1.000000   0.142857   0.250000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary = pd.DataFrame([b1, b2, b3, b4, b5])\n",
    "binary.columns = ['ROC AUC Score','Accuracy', 'Recall', 'Precision', 'F-1 Score']\n",
    "binary.index = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']\n",
    "binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
