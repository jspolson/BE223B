{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "import tqdm\n",
    "import unicodedata\n",
    "import math\n",
    "\n",
    "\n",
    "#nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jsons_data = pd.DataFrame(columns = ['user_record_id', 'text', 'likes', 'replies', 'retweets'])\n",
    "tweets_concat = pd.DataFrame(columns = ['user_id', 'n_tweets', 'text', 'likes', 'replies', 'retweets'])\n",
    "\n",
    "#j = json.loads(input_file.read().decode(\"utf-8-sig\"))\n",
    "\n",
    "directory = '/Users/danieljohnsonjr/Desktop/PR_lab_mii/tweet_files/'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.json'):\n",
    "        df = pd.DataFrame(json.load(open(directory + str(filename))))\n",
    "        df['tweet_id'] = df['user_record_id'].map(str) + '_' + df.index.astype(str)\n",
    "        jsons_data = jsons_data.append(df) \n",
    "        tweets_concat = tweets_concat.append({'user_id':df.user_record_id.iloc[0], \n",
    "                                              'n_tweets': len(df.index),\n",
    "                                              'text':df['text'].str.cat(sep=', '), \n",
    "                                              'likes':df.likes.astype(int).sum(), \n",
    "                                              'replies':df.replies.astype(int).sum(), \n",
    "                                              'retweets':df.retweets.astype(int).sum()}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#jsons_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tweets_concat.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xe2 in position 32: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5e5de7664b94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#replace picture links\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'pic.twitter\\S+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' image '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'—–-…’0123456789'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#remove stop words, convert back to string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-5e5de7664b94>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m((char,))\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#replace picture links\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'pic.twitter\\S+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' image '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'—–-…’0123456789'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#remove stop words, convert back to string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 32: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "processed_text = []\n",
    "for text in tweets_concat.text:\n",
    "    #replace hyperlinks - leaves xa0 off for some reason\n",
    "    test = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', ' hyperlink ', text).replace(u'\\xa0', u'')\n",
    "    #replace mentions\n",
    "    test = re.sub(r'(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)', ' mention ', test)\n",
    "    #replace picture links\n",
    "    test = re.sub(r'pic.twitter\\S+', ' image ', test)\n",
    "    test = \"\".join((char for char in test if char not in string.punctuation + '—–-…’0123456789')).lower()\n",
    "    \n",
    "    #remove stop words, convert back to string\n",
    "    filtered_series = [w for w in word_tokenize(test) \n",
    "                         if not w in set(stopwords.words('english'))]\n",
    "    filtered_string = ' '.join(filtered_series)\n",
    "    \n",
    "    processed_text.append(filtered_string)\n",
    "\n",
    "tweets_concat['text'] = processed_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "sentiment = 0.0\n",
    "senti_list = []\n",
    "\n",
    "for text in tweets_concat.text:\n",
    "    ss = analyser.polarity_scores(text)\n",
    "    sentiment = ss['compound']\n",
    "    senti_list.append(sentiment)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(senti_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.994,\n",
       " -0.9628,\n",
       " -0.9997,\n",
       " 0.9985,\n",
       " 0.4067,\n",
       " 0.9997,\n",
       " 0.8802,\n",
       " 0.9858,\n",
       " 0.1007,\n",
       " 1.0,\n",
       " 0.9983,\n",
       " 0.0,\n",
       " 0.9186,\n",
       " 0.9827,\n",
       " 0.9976,\n",
       " -0.8265,\n",
       " -0.9987,\n",
       " 0.4028,\n",
       " -0.9983,\n",
       " 0.9988,\n",
       " 0.6671,\n",
       " 0.4404,\n",
       " 0.8755,\n",
       " -0.9129,\n",
       " 0.9863,\n",
       " -0.9985,\n",
       " 0.9249,\n",
       " 0.7783,\n",
       " -0.8346,\n",
       " 0.6431,\n",
       " -0.4696,\n",
       " 0.996,\n",
       " -0.6465,\n",
       " -0.3182,\n",
       " 0.7339,\n",
       " 0.9997,\n",
       " 0.296,\n",
       " -0.9977,\n",
       " 0.997,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.9901,\n",
       " 0.9409,\n",
       " 0.9749,\n",
       " 0.9637,\n",
       " -0.6113,\n",
       " 0.9933,\n",
       " 0.5719,\n",
       " 0.9808,\n",
       " 0.8271,\n",
       " -0.0878,\n",
       " 0.908,\n",
       " 0.9582,\n",
       " 0.9988,\n",
       " 0.9861,\n",
       " 0.711,\n",
       " -0.296,\n",
       " -0.9786,\n",
       " 0.7717,\n",
       " 0.9958,\n",
       " 0.9996,\n",
       " 1.0,\n",
       " -0.7053,\n",
       " 0.9999,\n",
       " 0.0,\n",
       " -0.9961,\n",
       " 0.9558,\n",
       " 0.8872,\n",
       " 0.0,\n",
       " -0.765,\n",
       " 0.9948,\n",
       " 0.8402,\n",
       " 0.7698,\n",
       " 1.0,\n",
       " 0.4588,\n",
       " 0.8568,\n",
       " 0.9992,\n",
       " 0.9902,\n",
       " 0.9912,\n",
       " 0.9912,\n",
       " 0.7627,\n",
       " -0.6416,\n",
       " 0.3769,\n",
       " -0.296,\n",
       " -0.2354,\n",
       " 0.9986,\n",
       " 0.9845,\n",
       " -0.9903,\n",
       " 0.3612,\n",
       " -0.9978,\n",
       " 0.9151,\n",
       " -0.8283,\n",
       " 0.0,\n",
       " -0.998,\n",
       " 0.9995,\n",
       " 0.9723,\n",
       " -0.9856,\n",
       " 0.998,\n",
       " 0.9803,\n",
       " 0.9042,\n",
       " -0.9997,\n",
       " -0.9382,\n",
       " 0.9453,\n",
       " -0.9999,\n",
       " 0.9152,\n",
       " 0.9999,\n",
       " 0.525,\n",
       " 0.0,\n",
       " 0.9739,\n",
       " 0.9346,\n",
       " 0.9997,\n",
       " 0.7512,\n",
       " 0.9999,\n",
       " 0.5106,\n",
       " 0.9151,\n",
       " -0.9977,\n",
       " 0.9915,\n",
       " -0.9992,\n",
       " 0.7269,\n",
       " 0.5859,\n",
       " -0.974,\n",
       " 0.5719,\n",
       " 0.9956,\n",
       " -0.9826,\n",
       " 0.7402,\n",
       " 0.9737,\n",
       " 0.5994,\n",
       " 0.8122,\n",
       " 1.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
