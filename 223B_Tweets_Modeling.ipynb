{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import (wordnet, stopwords)\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import (LogisticRegression, LogisticRegressionCV)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import (confusion_matrix, \n",
    "                             recall_score, \n",
    "                             f1_score, \n",
    "                             accuracy_score, \n",
    "                             precision_score,\n",
    "                             roc_curve, auc, roc_auc_score)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import *\n",
    "from bisect import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['likes',\n",
       " 'n_tweets',\n",
       " 'replies',\n",
       " 'retweets',\n",
       " 'time_business',\n",
       " 'time_early',\n",
       " 'time_evening',\n",
       " 'time_late',\n",
       " 'weekday_mean',\n",
       " 'wkday_0',\n",
       " 'wkday_1',\n",
       " 'wkday_2',\n",
       " 'wkday_3',\n",
       " 'wkday_4',\n",
       " 'wkday_5',\n",
       " 'wkday_6',\n",
       " 'LDA_0',\n",
       " 'LDA_1',\n",
       " 'LDA_2',\n",
       " 'LDA_3',\n",
       " 'LDA_4',\n",
       " 'LDA_5',\n",
       " 'LDA_6',\n",
       " 'LDA_7',\n",
       " 'LDA_8',\n",
       " 'LDA_9',\n",
       " 'LDA_10',\n",
       " 'LDA_11',\n",
       " 'LDA_12',\n",
       " 'LDA_13',\n",
       " 'LDA_14',\n",
       " 'LDA_15',\n",
       " 'LDA_16',\n",
       " 'LDA_17',\n",
       " 'LDA_18',\n",
       " 'LDA_19',\n",
       " 'act',\n",
       " 'actual',\n",
       " 'aint',\n",
       " 'alreadi',\n",
       " 'alway',\n",
       " 'amaz',\n",
       " 'ani',\n",
       " 'annoy',\n",
       " 'anoth',\n",
       " 'answer',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anyth',\n",
       " 'ask',\n",
       " 'ass',\n",
       " 'away',\n",
       " 'babi',\n",
       " 'bad',\n",
       " 'beat',\n",
       " 'beauti',\n",
       " 'becaus',\n",
       " 'becom',\n",
       " 'bed',\n",
       " 'befor',\n",
       " 'believ',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'birthday',\n",
       " 'bitch',\n",
       " 'black',\n",
       " 'bless',\n",
       " 'block',\n",
       " 'bodi',\n",
       " 'bore',\n",
       " 'bout',\n",
       " 'boy',\n",
       " 'break',\n",
       " 'bring',\n",
       " 'bro',\n",
       " 'broke',\n",
       " 'busi',\n",
       " 'buy',\n",
       " 'came',\n",
       " 'car',\n",
       " 'care',\n",
       " 'catch',\n",
       " 'caus',\n",
       " 'chang',\n",
       " 'check',\n",
       " 'child',\n",
       " 'chill',\n",
       " 'close',\n",
       " 'cold',\n",
       " 'color',\n",
       " 'come',\n",
       " 'cool',\n",
       " 'coupl',\n",
       " 'cousin',\n",
       " 'crazi',\n",
       " 'cri',\n",
       " 'current',\n",
       " 'cute',\n",
       " 'damn',\n",
       " 'date',\n",
       " 'day',\n",
       " 'dead',\n",
       " 'deep',\n",
       " 'definit',\n",
       " 'deserv',\n",
       " 'didnt',\n",
       " 'die',\n",
       " 'differ',\n",
       " 'doe',\n",
       " 'doesnt',\n",
       " 'dont',\n",
       " 'drink',\n",
       " 'dumb',\n",
       " 'ear',\n",
       " 'eat',\n",
       " 'el',\n",
       " 'end',\n",
       " 'enjoy',\n",
       " 'everi',\n",
       " 'everybodi',\n",
       " 'everyday',\n",
       " 'everyon',\n",
       " 'everyth',\n",
       " 'exact',\n",
       " 'excit',\n",
       " 'face',\n",
       " 'fact',\n",
       " 'fake',\n",
       " 'fall',\n",
       " 'famili',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'favorit',\n",
       " 'feel',\n",
       " 'felt',\n",
       " 'fight',\n",
       " 'final',\n",
       " 'finish',\n",
       " 'fix',\n",
       " 'follow',\n",
       " 'food',\n",
       " 'forev',\n",
       " 'forget',\n",
       " 'free',\n",
       " 'friend',\n",
       " 'fuck',\n",
       " 'fun',\n",
       " 'funi',\n",
       " 'game',\n",
       " 'gave',\n",
       " 'girl',\n",
       " 'goal',\n",
       " 'god',\n",
       " 'gon',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'got',\n",
       " 'great',\n",
       " 'grow',\n",
       " 'guess',\n",
       " 'guy',\n",
       " 'hair',\n",
       " 'hand',\n",
       " 'hang',\n",
       " 'hapi',\n",
       " 'happen',\n",
       " 'hard',\n",
       " 'hate',\n",
       " 'head',\n",
       " 'hear',\n",
       " 'heart',\n",
       " 'hell',\n",
       " 'help',\n",
       " 'hes',\n",
       " 'hey',\n",
       " 'high',\n",
       " 'hit',\n",
       " 'hold',\n",
       " 'home',\n",
       " 'honest',\n",
       " 'hope',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'hous',\n",
       " 'hungri',\n",
       " 'hurt',\n",
       " 'hyperlink',\n",
       " 'ice',\n",
       " 'idk',\n",
       " 'ill',\n",
       " 'im',\n",
       " 'ima',\n",
       " 'imag',\n",
       " 'instead',\n",
       " 'isnt',\n",
       " 'ive',\n",
       " 'job',\n",
       " 'joke',\n",
       " 'kid',\n",
       " 'kill',\n",
       " 'knew',\n",
       " 'know',\n",
       " 'ladi',\n",
       " 'late',\n",
       " 'laugh',\n",
       " 'learn',\n",
       " 'leav',\n",
       " 'left',\n",
       " 'let',\n",
       " 'lie',\n",
       " 'life',\n",
       " 'like',\n",
       " 'lil',\n",
       " 'line',\n",
       " 'list',\n",
       " 'listen',\n",
       " 'liter',\n",
       " 'litl',\n",
       " 'live',\n",
       " 'lmao',\n",
       " 'lol',\n",
       " 'long',\n",
       " 'look',\n",
       " 'lose',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'mad',\n",
       " 'major',\n",
       " 'make',\n",
       " 'man',\n",
       " 'mani',\n",
       " 'matter',\n",
       " 'mayb',\n",
       " 'mean',\n",
       " 'meet',\n",
       " 'men',\n",
       " 'mention',\n",
       " 'mess',\n",
       " 'mind',\n",
       " 'miss',\n",
       " 'mom',\n",
       " 'moment',\n",
       " 'money',\n",
       " 'month',\n",
       " 'mood',\n",
       " 'morn',\n",
       " 'movi',\n",
       " 'na',\n",
       " 'need',\n",
       " 'new',\n",
       " 'nice',\n",
       " 'nigga',\n",
       " 'night',\n",
       " 'nobodi',\n",
       " 'noth',\n",
       " 'number',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'omg',\n",
       " 'onc',\n",
       " 'open',\n",
       " 'order',\n",
       " 'outa',\n",
       " 'parti',\n",
       " 'past',\n",
       " 'pay',\n",
       " 'peopl',\n",
       " 'person',\n",
       " 'phili',\n",
       " 'phone',\n",
       " 'photo',\n",
       " 'pick',\n",
       " 'pictur',\n",
       " 'pl',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'play',\n",
       " 'plea',\n",
       " 'point',\n",
       " 'pop',\n",
       " 'post',\n",
       " 'preti',\n",
       " 'probabl',\n",
       " 'problem',\n",
       " 'pull',\n",
       " 'quick',\n",
       " 'read',\n",
       " 'readi',\n",
       " 'real',\n",
       " 'reali',\n",
       " 'realiz',\n",
       " 'reason',\n",
       " 'rememb',\n",
       " 'remind',\n",
       " 'rest',\n",
       " 'ride',\n",
       " 'right',\n",
       " 'room',\n",
       " 'run',\n",
       " 'said',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'school',\n",
       " 'second',\n",
       " 'seen',\n",
       " 'send',\n",
       " 'set',\n",
       " 'share',\n",
       " 'shit',\n",
       " 'shot',\n",
       " 'sick',\n",
       " 'sign',\n",
       " 'sinc',\n",
       " 'sit',\n",
       " 'situat',\n",
       " 'sleep',\n",
       " 'smh',\n",
       " 'social',\n",
       " 'somebodi',\n",
       " 'someon',\n",
       " 'someth',\n",
       " 'song',\n",
       " 'soon',\n",
       " 'sori',\n",
       " 'sound',\n",
       " 'speak',\n",
       " 'stand',\n",
       " 'start',\n",
       " 'state',\n",
       " 'stay',\n",
       " 'stop',\n",
       " 'street',\n",
       " 'stuff',\n",
       " 'support',\n",
       " 'sure',\n",
       " 'surpri',\n",
       " 'ta',\n",
       " 'talk',\n",
       " 'tell',\n",
       " 'th',\n",
       " 'thank',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'tho',\n",
       " 'thought',\n",
       " 'throw',\n",
       " 'time',\n",
       " 'tire',\n",
       " 'today',\n",
       " 'togeth',\n",
       " 'told',\n",
       " 'tomorrow',\n",
       " 'tonight',\n",
       " 'took',\n",
       " 'tri',\n",
       " 'trip',\n",
       " 'true',\n",
       " 'trump',\n",
       " 'trust',\n",
       " 'tryna',\n",
       " 'turn',\n",
       " 'tweet',\n",
       " 'twitter',\n",
       " 'type',\n",
       " 'understand',\n",
       " 'use',\n",
       " 'veri',\n",
       " 'video',\n",
       " 'wait',\n",
       " 'walk',\n",
       " 'wan',\n",
       " 'want',\n",
       " 'wasnt',\n",
       " 'watch',\n",
       " 'way',\n",
       " 'wear',\n",
       " 'week',\n",
       " 'weekend',\n",
       " 'weird',\n",
       " 'went',\n",
       " 'whi',\n",
       " 'white',\n",
       " 'win',\n",
       " 'wish',\n",
       " 'wonder',\n",
       " 'wont',\n",
       " 'word',\n",
       " 'work',\n",
       " 'world',\n",
       " 'wow',\n",
       " 'wrong',\n",
       " 'ya',\n",
       " 'yal',\n",
       " 'yeah',\n",
       " 'year',\n",
       " 'yes',\n",
       " 'yo',\n",
       " 'young',\n",
       " 'Negative Sentiment',\n",
       " 'Positive Sentiment',\n",
       " 'Neutral Sentiment',\n",
       " 'variable',\n",
       " 'ratio',\n",
       " 'binary_label']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email = pd.read_csv('features_id_text.csv')\n",
    "#email.index = email['Unnamed: 0']\n",
    "email = email.drop('Unnamed: 0', axis = 1)\n",
    "list(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data = email\n",
    "#drop the user in turkish\n",
    "full_data = full_data.drop(full_data[full_data.index == 2697].index)\n",
    "#drop not common tweeters\n",
    "#full_data = full_data.drop(full_data[full_data.n_tweets == 1].index)\n",
    "#full_data = full_data.drop(full_data[full_data.n_tweets > 800].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_folds(full_data, n_folds, rand = 15): \n",
    "    X = full_data.drop(['variable', 'binary_label'], axis = 1).as_matrix()\n",
    "    y = full_data.as_matrix(['binary_label'])\n",
    "    ints = [list(test_index) \n",
    "            for train_index, test_index in StratifiedKFold(n_folds, shuffle = True, random_state = rand).split(X, y)]\n",
    "    return [full_data.iloc[ints[i],:] for i in range(n_folds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_metrics (test, label, pred):\n",
    "    acc = accuracy_score(test[label], test[pred])\n",
    "    f1 = f1_score(test[label], test[pred])\n",
    "    prec = precision_score(test[label], test[pred])\n",
    "    rec = recall_score(test[label], test[pred])\n",
    "    roc_auc = roc_auc_score(test[label], test[pred])\n",
    "    \n",
    "    return roc_auc, acc, prec, rec, f1\n",
    "\n",
    "def plot_metrics (test, label, pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(test[label], test[pred]).ravel()\n",
    "    roc_auc, acc, prec, rec, f1 = binary_metrics(test, label, pred)\n",
    "    roc = roc_curve(test[label], test[pred])\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(test[label].nunique()):\n",
    "        fpr[i], tpr[i], _ = roc_curve(test[label], test[pred])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test[label].ravel(), test[pred].ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    lw = 2\n",
    "    plt.plot(fpr[1], tpr[1], color='gold',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "    show_confusion_matrix(test, label, pred)\n",
    "    \n",
    "    return roc_auc[0], acc, prec, rec, f1\n",
    "\n",
    "def show_confusion_matrix(test, label, pred):\n",
    "    \n",
    "    C = confusion_matrix(test[label], test[pred])\n",
    "    tn, fp, fn, tp = C.ravel()\n",
    "    \n",
    "    NP = fn+tp # Num positive examples\n",
    "    NN = tn+fp # Num negative examples\n",
    "    N  = NP+NN\n",
    "\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax  = fig.add_subplot(111)\n",
    "    ax.imshow(C, cmap=plt.cm.gray)\n",
    "\n",
    "    # Draw the grid boxes\n",
    "    ax.set_xlim(-0.5,2.5)\n",
    "    ax.set_ylim(2.5,-0.5)\n",
    "    ax.plot([-0.5,2.5],[0.5,0.5], '-k', lw=2)\n",
    "    ax.plot([-0.5,2.5],[1.5,1.5], '-k', lw=2)\n",
    "    ax.plot([0.5,0.5],[-0.5,2.5], '-k', lw=2)\n",
    "    ax.plot([1.5,1.5],[-0.5,2.5], '-k', lw=2)\n",
    "\n",
    "\n",
    "    # Set xlabels\n",
    "    ax.set_xlabel('Predicted Label', fontsize=16)\n",
    "    ax.set_xticks([0,1,2])\n",
    "    ax.set_xticklabels(['Show', 'No Show'])\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.xaxis.tick_top()\n",
    "    # These coordinate might require some tinkering. Ditto for y, below.\n",
    "    ax.xaxis.set_label_coords(0.34,1.06)\n",
    "\n",
    "    # Set ylabels\n",
    "    ax.set_ylabel('True Label', fontsize=16, rotation=90)\n",
    "    ax.set_yticklabels(['Bad', 'Good'])\n",
    "    ax.set_yticks([0,1,2])\n",
    "    ax.yaxis.set_label_coords(-0.09,0.65)\n",
    "\n",
    "\n",
    "    # Fill in initial metrics: tp, tn, etc...\n",
    "    ax.text(0,0,'True Negatives: %d\\n(Total Negatives: %d)'%(tn,NN),\n",
    "            va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "    ax.text(0,1,'False Negatives: %d'%fn,\n",
    "            va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "    ax.text(1,0,'False Positives: %d'%fp,\n",
    "           va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "    ax.text(1,1,'True Positives: %d\\n(Total Positives: %d)'%(tp,NP),\n",
    "            va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "    # Fill in secondary metrics: accuracy, true pos rate, etc...\n",
    "    ax.text(2,0,'True Negative Rate' + '\\n' +'(Specificity):%.2f'%(tn / (fp+tn+0.)),\n",
    "            va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "    ax.text(2,1,'True Positive Rate' + '\\n' + '(Sensitivity):%.2f'%(tp / (tp+fn+0.)),\n",
    "            va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "    ax.text(2,2,'F-1 Score: %.2f'%(round(2*tp/((2*tp) + fp + fn),3)),\n",
    "            va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "    ax.text(0,2,'Negative Predictive ' + '\\n' + 'Value: %.2f'%(1-fn/(fn+tn+0.)),\n",
    "           va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "    ax.text(1,2,'Positive Predictive ' + '\\n' + 'Value: %.2f'%(tp/(tp+fp+0.)),\n",
    "            va='center', ha='center', bbox=dict(fc='w',boxstyle='round,pad=1'))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_model_rfc (full, test, label, pred, plot = False):\n",
    "    train = pd.concat([full, test]).drop_duplicates(keep=False)\n",
    "    trainArr = train.drop(['variable', 'binary_label'], axis = 1).as_matrix()\n",
    "    trainRes = train.as_matrix(['binary_label'])\n",
    "    testArr = test.drop(['variable', 'binary_label'], axis = 1).as_matrix()\n",
    "    \n",
    "    param_test = {'n_estimators':np.arange(20,111,10).tolist(), \n",
    "                   'max_features':np.arange(0.1,1,0.1).tolist()\n",
    "                   , 'class_weight':['balanced', None]\n",
    "                   ,'criterion':['gini', 'entropy']\n",
    "                  }\n",
    "    gridsearch = GridSearchCV(estimator = RandomForestClassifier(random_state=10),\n",
    "                              param_grid = param_test, scoring = 'roc_auc', n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "    gridsearch.fit(trainArr,trainRes)\n",
    "    \n",
    "    predictions = gridsearch.predict(testArr)\n",
    "    \n",
    "    data = pd.DataFrame(list(test[label]),columns=[label], index = test.index)\n",
    "    data[pred] = pd.Series(list(predictions), index=data.index) \n",
    "    \n",
    "    if plot:\n",
    "        roc_auc, acc, prec, rec, f1 = plot_metrics(data, label, pred)\n",
    "    else:\n",
    "        roc_auc, acc, prec, rec, f1 = binary_metrics(data, label, pred)    \n",
    "    \n",
    "    return data, [roc_auc, acc, prec, rec, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_model(full, test, label, pred, plot = False, CV = False, rfe = True):\n",
    "    train = pd.concat([full, test]).drop_duplicates(keep=False)\n",
    "    trainArr = train.drop(['variable', 'binary_label'], axis = 1).as_matrix()\n",
    "    trainRes = train.as_matrix(['binary_label'])\n",
    "    testArr = test.drop(['variable', 'binary_label'], axis = 1).as_matrix()\n",
    "    \n",
    "    if CV:\n",
    "        estimator = LogisticRegressionCV(scoring = 'roc_auc')\n",
    "    else:\n",
    "        param_test = {'C':[0.0001,0.001,0.01,0.1,1,10,100,1000],\n",
    "                       'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "        gridsearch = GridSearchCV(estimator = LogisticRegression(class_weight = 'balanced'),\n",
    "                                  param_grid = param_test, scoring = 'roc_auc').fit(trainArr,trainRes)\n",
    "        estimator = LogisticRegression(C=list(gridsearch.best_params_.values())[0],\n",
    "                                       solver=list(gridsearch.best_params_.values())[1])\n",
    "    if rfe:\n",
    "        selector = RFE(estimator, step=1)\n",
    "    \n",
    "    else:\n",
    "        selector = estimator\n",
    "    \n",
    "    selector = selector.fit(trainArr, trainRes)\n",
    "    predictions = selector.predict(testArr)\n",
    "        \n",
    "    data = pd.DataFrame(list(test[label]),columns=[label], index = test.index)\n",
    "    data[pred] = pd.Series(list(predictions), index=data.index)                \n",
    "    \n",
    "    if plot:\n",
    "        roc_auc, acc, prec, rec, f1 = plot_metrics(data, label, pred)\n",
    "    else:\n",
    "        roc_auc, acc, prec, rec, f1 = binary_metrics(data, label, pred)\n",
    "    \n",
    "    return data, [roc_auc, acc, prec, rec, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fold1, fold2, fold3, fold4, fold5 = create_folds(full_data,5, rand = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC AUC Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F-1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold 1</th>\n",
       "      <td>0.478022</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 2</th>\n",
       "      <td>0.521978</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 3</th>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 4</th>\n",
       "      <td>0.521978</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 5</th>\n",
       "      <td>0.593407</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.534615</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.557925</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.524877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ROC AUC Score  Accuracy    Recall  Precision  F-1 Score\n",
       "Fold 1       0.478022  0.481481  0.500000   0.571429   0.533333\n",
       "Fold 2       0.521978  0.518519  0.545455   0.428571   0.480000\n",
       "Fold 3       0.557692  0.555556  0.583333   0.500000   0.538462\n",
       "Fold 4       0.521978  0.518519  0.545455   0.428571   0.480000\n",
       "Fold 5       0.593407  0.592593  0.615385   0.571429   0.592593\n",
       "Mean         0.534615  0.533333  0.557925   0.500000   0.524877"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label, pred = 'binary_label', 'predictions'\n",
    "\n",
    "t1, b1 = run_model_rfc(full_data, fold1, label, pred)\n",
    "t2, b2 = run_model_rfc(full_data, fold2, label, pred)\n",
    "t3, b3 = run_model_rfc(full_data, fold3, label, pred)\n",
    "t4, b4 = run_model_rfc(full_data, fold4, label, pred)\n",
    "t5, b5 = run_model_rfc(full_data, fold5, label, pred)\n",
    "\n",
    "binary = pd.DataFrame([b1, b2, b3, b4, b5])\n",
    "binary.columns = ['ROC AUC Score','Accuracy', 'Recall', 'Precision', 'F-1 Score']\n",
    "binary.index = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']\n",
    "binary.loc['Mean'] = binary.mean()\n",
    "binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC AUC Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F-1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold 1</th>\n",
       "      <td>0.478022</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 2</th>\n",
       "      <td>0.521978</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 3</th>\n",
       "      <td>0.601648</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.682927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 5</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.528022</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.563344</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.574490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ROC AUC Score  Accuracy    Recall  Precision  F-1 Score\n",
       "Fold 1       0.478022  0.481481  0.500000   0.571429   0.533333\n",
       "Fold 2       0.521978  0.518519  0.545455   0.428571   0.480000\n",
       "Fold 3       0.601648  0.592593  0.714286   0.357143   0.476190\n",
       "Fold 4       0.500000  0.518519  0.518519   1.000000   0.682927\n",
       "Fold 5       0.538462  0.555556  0.538462   1.000000   0.700000\n",
       "Mean         0.528022  0.533333  0.563344   0.671429   0.574490"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1, b1 = lr_model(full_data, fold1, label, pred, rfe = False)\n",
    "t2, b2 = lr_model(full_data, fold2, label, pred, rfe = False)\n",
    "t3, b3 = lr_model(full_data, fold3, label, pred, rfe = False)\n",
    "t4, b4 = lr_model(full_data, fold4, label, pred, rfe = False)\n",
    "t5, b5 = lr_model(full_data, fold5, label, pred, rfe = False)\n",
    "\n",
    "binary = pd.DataFrame([b1, b2, b3, b4, b5])\n",
    "binary.columns = ['ROC AUC Score','Accuracy', 'Recall', 'Precision', 'F-1 Score']\n",
    "binary.index = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']\n",
    "binary.loc['Mean'] = binary.mean()\n",
    "binary\n",
    "\n",
    "### inter fold variation\n",
    "### new models to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC AUC Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F-1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold 1</th>\n",
       "      <td>0.508242</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 2</th>\n",
       "      <td>0.480769</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 3</th>\n",
       "      <td>0.601648</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.476190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.682927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 5</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.525824</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.559015</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.597538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ROC AUC Score  Accuracy    Recall  Precision  F-1 Score\n",
       "Fold 1       0.508242  0.518519  0.523810   0.785714   0.628571\n",
       "Fold 2       0.480769  0.481481  0.500000   0.500000   0.500000\n",
       "Fold 3       0.601648  0.592593  0.714286   0.357143   0.476190\n",
       "Fold 4       0.500000  0.518519  0.518519   1.000000   0.682927\n",
       "Fold 5       0.538462  0.555556  0.538462   1.000000   0.700000\n",
       "Mean         0.525824  0.533333  0.559015   0.728571   0.597538"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1, b1 = lr_model(full_data, fold1, label, pred)\n",
    "t2, b2 = lr_model(full_data, fold2, label, pred)\n",
    "t3, b3 = lr_model(full_data, fold3, label, pred)\n",
    "t4, b4 = lr_model(full_data, fold4, label, pred)\n",
    "t5, b5 = lr_model(full_data, fold5, label, pred)\n",
    "\n",
    "binary = pd.DataFrame([b1, b2, b3, b4, b5])\n",
    "binary.columns = ['ROC AUC Score','Accuracy', 'Recall', 'Precision', 'F-1 Score']\n",
    "binary.index = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']\n",
    "binary.loc['Mean'] = binary.mean()\n",
    "binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def model_gbc (full, test, label, pred, plot = False, CV = False, rfe = True):\n",
    "    train = pd.concat([full, test]).drop_duplicates(keep=False)\n",
    "    trainArr = train.drop(['variable', 'binary_label'], axis = 1).as_matrix()\n",
    "    trainRes = train.as_matrix(['binary_label'])\n",
    "    testArr = test.drop(['variable', 'binary_label'], axis = 1).as_matrix()\n",
    "    \n",
    "    lr = 1\n",
    "    min_samples_leaf = 1\n",
    "    \n",
    "    #NUMBER OF ESTIMATORS\n",
    "    param_test1 = {'n_estimators':np.arange(500,4000,500).tolist()}\n",
    "    gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=lr, min_samples_split=500,\n",
    "                              min_samples_leaf=50,max_depth=8,max_features='sqrt', subsample=0.8,random_state=10), \n",
    "                   param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "    gsearch1.fit(trainArr, trainRes)\n",
    "    n_estimators = list(gsearch1.best_params_.values())[0]\n",
    "    display(gsearch1.best_params_)\n",
    "\n",
    "    param_test2 = {'max_depth':list(range(1,16,1)), 'min_samples_split':list(range(2,10,1))}\n",
    "    gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=lr, n_estimators=n_estimators,\n",
    "                                            max_features='sqrt', subsample=0.8, random_state=10), \n",
    "                   param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "    gsearch2.fit(trainArr, trainRes)\n",
    "    display(gsearch2.best_params_)\n",
    "    max_depth=list(gsearch2.best_params_.values())[0]\n",
    "    min_samples_split = list(gsearch2.best_params_.values())[1]\n",
    "\n",
    "    #Grid seach on subsample and max_features\n",
    "    param_test3 = {'learning_rate':[0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
    "    gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=lr, n_estimators=n_estimators,max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                                                max_features='sqrt', subsample=0.8, random_state=10), \n",
    "                   param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "    gsearch3.fit(trainArr, trainRes)\n",
    "    display(gsearch3.best_params_)\n",
    "    lr = list(gsearch3.best_params_.values())[0]\n",
    "\n",
    "    #Grid seach on subsample and max_features\n",
    "    param_test4 = {'max_features':[0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]}\n",
    "    gsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=lr, n_estimators=n_estimators,max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                                                min_samples_leaf=min_samples_leaf, subsample=0.8, random_state=10), \n",
    "                   param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "    gsearch4.fit(trainArr, trainRes)\n",
    "    display(gsearch4.best_params_)\n",
    "    max_features = list(gsearch4.best_params_.values())[0]\n",
    "\n",
    "    #Grid seach on subsample and max_features\n",
    "    param_test5 = {'subsample':[0.6,0.7,0.75,0.8,0.85,0.9]}\n",
    "    gsearch5=GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=lr, n_estimators=n_estimators,max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                                                min_samples_leaf=min_samples_leaf,max_features=max_features, random_state=10), \n",
    "                   param_grid = param_test5, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "    gsearch5.fit(trainArr, trainRes)\n",
    "    display(gsearch5.best_params_)\n",
    "    subsample = list(gsearch5.best_params_.values())[0]\n",
    "    \n",
    "    selector=GradientBoostingClassifier(learning_rate=lr, n_estimators=n_estimators*100, max_depth=max_depth, min_samples_split=min_samples_split,\n",
    "                                                subsample=subsample, max_features=max_features, min_samples_leaf=min_samples_leaf, random_state=10)\n",
    "    \n",
    "    selector = selector.fit(trainArr, trainRes)\n",
    "    predictions = selector.predict(testArr)\n",
    "        \n",
    "    data = pd.DataFrame(list(test[label]),columns=[label], index = test.index)\n",
    "    data[pred] = pd.Series(list(predictions), index=data.index)                \n",
    "    \n",
    "    if plot:\n",
    "        roc_auc, acc, prec, rec, f1 = plot_metrics(data, label, pred)\n",
    "    else:\n",
    "        roc_auc, acc, prec, rec, f1 = binary_metrics(data, label, pred)\n",
    "    \n",
    "    return data, [roc_auc, acc, prec, rec, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 2, 'min_samples_split': 3}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.7}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.8}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'min_samples_split': 7}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.9}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.8}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'min_samples_split': 7}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.8}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.8}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10, 'min_samples_split': 2}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.6}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.5}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.8}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'min_samples_split': 4}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1.0}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_features': 0.9}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'subsample': 0.8}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC AUC Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F-1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold 1</th>\n",
       "      <td>0.585165</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 2</th>\n",
       "      <td>0.596154</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 3</th>\n",
       "      <td>0.524725</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 4</th>\n",
       "      <td>0.409341</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 5</th>\n",
       "      <td>0.552198</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.533516</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.550007</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.529213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ROC AUC Score  Accuracy    Recall  Precision  F-1 Score\n",
       "Fold 1       0.585165  0.592593  0.578947   0.785714   0.666667\n",
       "Fold 2       0.596154  0.592593  0.636364   0.500000   0.560000\n",
       "Fold 3       0.524725  0.518519  0.555556   0.357143   0.434783\n",
       "Fold 4       0.409341  0.407407  0.416667   0.357143   0.384615\n",
       "Fold 5       0.552198  0.555556  0.562500   0.642857   0.600000\n",
       "Mean         0.533516  0.533333  0.550007   0.528571   0.529213"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1, b1 = model_gbc(full_data, fold1, label, pred)\n",
    "t2, b2 = model_gbc(full_data, fold2, label, pred)\n",
    "t3, b3 = model_gbc(full_data, fold3, label, pred)\n",
    "t4, b4 = model_gbc(full_data, fold4, label, pred)\n",
    "t5, b5 = model_gbc(full_data, fold5, label, pred)\n",
    "\n",
    "binary = pd.DataFrame([b1, b2, b3, b4, b5])\n",
    "binary.columns = ['ROC AUC Score','Accuracy', 'Recall', 'Precision', 'F-1 Score']\n",
    "binary.index = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']\n",
    "binary.loc['Mean'] = binary.mean()\n",
    "binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gb_model (full, test, label, pred, plot = False, CV = False):\n",
    "    train = pd.concat([full, test]).drop_duplicates(keep=False)\n",
    "    trainArr = train.drop(['variable', 'binary_label'], axis = 1).as_matrix()\n",
    "    trainRes = train.as_matrix(['binary_label'])\n",
    "    testArr = test.drop(['variable', 'binary_label'], axis = 1).as_matrix()\n",
    "    \n",
    "    if CV:\n",
    "        #GRIDSEARCH\n",
    "        params = {'n_estimators':np.arange(100,15000,500).tolist(),\n",
    "                  #'max_depth':list(range(1,16,1)), \n",
    "                  #'min_samples_split':list(range(2,10,1)),\n",
    "                  #'max_features':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "                  #'subsample':[0.6,0.7,0.75,0.8,0.85,0.9],\n",
    "                  'learning_rate': np.arange(0.05,1,0.05).tolist()}\n",
    "        estimator = GridSearchCV(estimator = GradientBoostingClassifier(criterion = 'mse', random_state = 15), scoring='roc_auc', param_grid = params).fit(trainArr, trainRes)\n",
    "        \n",
    "        print('Gridsearch completed! Parameters are:')\n",
    "        print(estimator.best_params_)\n",
    "    else:\n",
    "        estimator = GradientBoostingClassifier(n_estimators = 5000,\n",
    "                                               learning_rate = 0.005,\n",
    "                                               random_state = 18).fit(trainArr, trainRes)\n",
    "        #print('Gridsearch not run. Parameters are:')\n",
    "        #print(estimator.get_params)\n",
    "    \n",
    "    predictions = estimator.predict(testArr)\n",
    "        \n",
    "    data = pd.DataFrame(list(test[label]),columns=[label], index = test.index)\n",
    "    data[pred] = pd.Series(list(predictions), index=data.index)                \n",
    "    \n",
    "    if plot:\n",
    "        roc_auc, acc, prec, rec, f1 = plot_metrics(data, label, pred)\n",
    "    else:\n",
    "        roc_auc, acc, prec, rec, f1 = binary_metrics(data, label, pred)\n",
    "    \n",
    "    return data, [roc_auc, acc, prec, rec, f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROC AUC Score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F-1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fold 1</th>\n",
       "      <td>0.620879</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 2</th>\n",
       "      <td>0.598901</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.521739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 3</th>\n",
       "      <td>0.629121</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 4</th>\n",
       "      <td>0.409341</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold 5</th>\n",
       "      <td>0.667582</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.585165</td>\n",
       "      <td>0.585185</td>\n",
       "      <td>0.603700</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>0.584352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ROC AUC Score  Accuracy    Recall  Precision  F-1 Score\n",
       "Fold 1       0.620879  0.629630  0.600000   0.857143   0.705882\n",
       "Fold 2       0.598901  0.592593  0.666667   0.428571   0.521739\n",
       "Fold 3       0.629121  0.629630  0.642857   0.642857   0.642857\n",
       "Fold 4       0.409341  0.407407  0.416667   0.357143   0.384615\n",
       "Fold 5       0.667582  0.666667  0.692308   0.642857   0.666667\n",
       "Mean         0.585165  0.585185  0.603700   0.585714   0.584352"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1, b1 = gb_model(full_data, fold1, label, pred)\n",
    "t2, b2 = gb_model(full_data, fold2, label, pred)\n",
    "t3, b3 = gb_model(full_data, fold3, label, pred)\n",
    "t4, b4 = gb_model(full_data, fold4, label, pred)\n",
    "t5, b5 = gb_model(full_data, fold5, label, pred)\n",
    "\n",
    "binary = pd.DataFrame([b1, b2, b3, b4, b5])\n",
    "binary.columns = ['ROC AUC Score','Accuracy', 'Recall', 'Precision', 'F-1 Score']\n",
    "binary.index = ['Fold 1', 'Fold 2', 'Fold 3', 'Fold 4', 'Fold 5']\n",
    "binary.loc['Mean'] = binary.mean()\n",
    "binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
